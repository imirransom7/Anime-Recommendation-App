{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4db919b-5b1f-4741-a553-8844a83a5319",
   "metadata": {},
   "source": [
    "# **Machine Learning Recommendation Model**\n",
    "This model will be trained using data from user's ratings of a variety of anime\n",
    "### Imports\n",
    "Setting up the imports that will be needed for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ab18fb-ec0d-4bd3-91e6-9e08dd462ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df8925-b305-4a9c-88b5-f740f575a36c",
   "metadata": {},
   "source": [
    "## **Model Training**\n",
    "### Spark Session\n",
    "Creating a spark session by creating a spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08869f21-59aa-455e-9695-9524f3a21b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "            .appName('RecAnime') \\\n",
    "            .config('spark.driver.memory', '4g') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3d5a6-9a0d-40d7-834e-c9f900924caf",
   "metadata": {},
   "source": [
    "### Spark DataFrame\n",
    "Reading the csv file, `user-score-2023`, into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcaa7e7-a430-46ee-9d03-8e7c35892a7a",
   "metadata": {},
   "source": [
    "The parameter `header=True` indicates the first row of the csv file contains the column names. Setting it to True means the first row will be the header, and the columns nanmes will be inferred from it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c81deb-3170-464c-8cab-d67e480b1bf0",
   "metadata": {},
   "source": [
    "The parameter `inferSchema` tells Spark to automatically infer the data types of the columns in the\n",
    "DataFrame based on the contents of the csv file. When set to True, Spark will try to determine the\n",
    "data appropriate data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a348b53-c170-4365-83d7-410edb4ee299",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('E:/RhaMo/CSV Files/Anime Dataset/user-filtered.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9aeca7-acef-4ed1-9b56-93cb7683fce0",
   "metadata": {},
   "source": [
    "Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f92648d-ed1e-4ddc-a803-49325d6e673f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=0, anime_id=67, rating=9),\n",
       " Row(user_id=0, anime_id=6702, rating=7),\n",
       " Row(user_id=0, anime_id=242, rating=10),\n",
       " Row(user_id=0, anime_id=4898, rating=0),\n",
       " Row(user_id=0, anime_id=21, rating=10),\n",
       " Row(user_id=0, anime_id=24, rating=9),\n",
       " Row(user_id=0, anime_id=2104, rating=0),\n",
       " Row(user_id=0, anime_id=4722, rating=8),\n",
       " Row(user_id=0, anime_id=6098, rating=6),\n",
       " Row(user_id=0, anime_id=3125, rating=9)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afff36ac-9bf3-4f38-944f-362c0b8487c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=353404, anime_id=986, rating=9),\n",
       " Row(user_id=353404, anime_id=985, rating=7),\n",
       " Row(user_id=353404, anime_id=287, rating=9),\n",
       " Row(user_id=353404, anime_id=551, rating=8),\n",
       " Row(user_id=353404, anime_id=243, rating=7),\n",
       " Row(user_id=353404, anime_id=507, rating=7),\n",
       " Row(user_id=353404, anime_id=392, rating=9),\n",
       " Row(user_id=353404, anime_id=882, rating=6),\n",
       " Row(user_id=353404, anime_id=883, rating=8),\n",
       " Row(user_id=353404, anime_id=149, rating=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9a586-371f-48c3-bf20-1efd941f962b",
   "metadata": {},
   "source": [
    "### Load Sample Data\n",
    "Since the data I am using is large, I will need to train the model with a subset of the data I have so that I can scale it up from there. I will use the sample to start off training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ddd7ac-0d5c-420d-ac0e-aaaf494e5b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
